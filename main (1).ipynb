{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import Ridge\n",
        "from tqdm.auto import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "2KRYHD7GJzm3"
      },
      "id": "2KRYHD7GJzm3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Config:\n",
        "    \"\"\"Centralized configuration\"\"\"\n",
        "    EMBEDDING_MODEL = \"intfloat/multilingual-e5-large\"\n",
        "    EMBEDDING_DIM = 1024\n",
        "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "    # Training parameters\n",
        "    NUM_EPOCHS = 20\n",
        "    BATCH_SIZE = 256\n",
        "    LEARNING_RATE = 0.001\n",
        "    NUM_FOLDS = 5\n",
        "    RANDOM_SEED = 42\n",
        "\n",
        "    # Augmentation parameters\n",
        "    NOISE_SCALE = 0.6\n",
        "    NEG_SAMPLE_RATIO = 3  # How many negative samples per positive"
      ],
      "metadata": {
        "id": "W64uMQdOd5h1"
      },
      "id": "W64uMQdOd5h1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# DATA LOADING & PREPROCESSING\n",
        "# =====================================\n",
        "\n",
        "def load_dataset_files():\n",
        "    \"\"\"Load all required JSON files\"\"\"\n",
        "    with open(\"train_data.json\", \"r\", encoding=\"utf8\") as f:\n",
        "        train_data = json.load(f)\n",
        "\n",
        "    with open(\"test_data.json\", \"r\", encoding=\"utf8\") as f:\n",
        "        test_data = json.load(f)\n",
        "\n",
        "    with open(\"metric_names.json\", \"r\", encoding=\"utf8\") as f:\n",
        "        metric_lookup = json.load(f)\n",
        "\n",
        "    return pd.DataFrame(train_data), pd.DataFrame(test_data), metric_lookup"
      ],
      "metadata": {
        "id": "BUOaoEPkeC_7"
      },
      "id": "BUOaoEPkeC_7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_combined_text(dataframe):\n",
        "    \"\"\"Merge system prompt, user query, and response into one text\"\"\"\n",
        "    def merge_fields(row):\n",
        "        system = str(row.get(\"system_prompt\", \"\")) if pd.notna(row.get(\"system_prompt\")) else \"\"\n",
        "        user = str(row.get(\"user_prompt\", \"\"))\n",
        "        response = str(row.get(\"response\", \"\"))\n",
        "\n",
        "        # Custom separator tokens for better semantic parsing\n",
        "        return f\"{system} <SYS> {user} <USER> {response} <RESP>\"\n",
        "\n",
        "    dataframe[\"full_text\"] = dataframe.apply(merge_fields, axis=1)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "xxuLysbTeC9b"
      },
      "id": "xxuLysbTeC9b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# EMBEDDING GENERATION\n",
        "# =====================================\n",
        "\n",
        "class EmbeddingGenerator:\n",
        "    \"\"\"Handles all embedding generation tasks\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, device='cuda'):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "        self.model = self.model.to(device)\n",
        "        self.device = device\n",
        "\n",
        "    def encode_batch(self, texts, batch_size=64, show_progress=False):\n",
        "        \"\"\"Encode a list of texts to embeddings\"\"\"\n",
        "        embeddings = self.model.encode(\n",
        "            texts,\n",
        "            batch_size=batch_size,\n",
        "            convert_to_numpy=True,\n",
        "            show_progress_bar=show_progress,\n",
        "            device=self.device\n",
        "        )\n",
        "        return embeddings.astype(np.float32)\n",
        "\n",
        "    def encode_metrics(self, metric_list):\n",
        "        \"\"\"Create embeddings for unique metric names\"\"\"\n",
        "        unique_metrics = list(set(metric_list))\n",
        "        print(f\"Encoding {len(unique_metrics)} unique metrics...\")\n",
        "\n",
        "        metric_embeddings = {}\n",
        "        for i in tqdm(range(0, len(unique_metrics), 64)):\n",
        "            batch = unique_metrics[i:i+64]\n",
        "            batch_emb = self.encode_batch(batch)\n",
        "\n",
        "            for metric, emb in zip(batch, batch_emb):\n",
        "                metric_embeddings[metric] = emb\n",
        "\n",
        "        return metric_embeddings"
      ],
      "metadata": {
        "id": "fViO_B0keC65"
      },
      "id": "fViO_B0keC65",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# NEGATIVE SAMPLE GENERATION\n",
        "# =====================================\n",
        "\n",
        "def generate_negative_samples(metric_embs, text_embs, labels, config):\n",
        "    \"\"\"Create synthetic negative samples using multiple strategies\"\"\"\n",
        "\n",
        "    rng = np.random.default_rng(config.RANDOM_SEED)\n",
        "    n_samples = len(metric_embs)\n",
        "\n",
        "    # Strategy 1: Random shuffling (breaks correct pairing)\n",
        "    shuffled_indices = rng.permutation(n_samples)\n",
        "    neg_metrics_v1 = metric_embs.copy()\n",
        "    neg_text_v1 = text_embs[shuffled_indices]\n",
        "    neg_labels_v1 = rng.integers(0, 3, size=n_samples).astype(np.float32)\n",
        "\n",
        "    # Strategy 2: Add Gaussian noise to text embeddings\n",
        "    noise = rng.normal(loc=0, scale=config.NOISE_SCALE, size=text_embs.shape)\n",
        "    neg_metrics_v2 = metric_embs.copy()\n",
        "    neg_text_v2 = text_embs + noise\n",
        "    neg_labels_v2 = rng.integers(0, 3, size=n_samples).astype(np.float32)\n",
        "\n",
        "    # Strategy 3: Swap metric embeddings\n",
        "    metric_shuffle = rng.permutation(n_samples)\n",
        "    neg_metrics_v3 = metric_embs[metric_shuffle]\n",
        "    neg_text_v3 = text_embs.copy()\n",
        "    neg_labels_v3 = rng.integers(0, 3, size=n_samples).astype(np.float32)\n",
        "\n",
        "    # Combine all samples\n",
        "    all_metric_embs = np.vstack([\n",
        "        metric_embs, neg_metrics_v1, neg_metrics_v2, neg_metrics_v3\n",
        "    ])\n",
        "\n",
        "    all_text_embs = np.vstack([\n",
        "        text_embs, neg_text_v1, neg_text_v2, neg_text_v3\n",
        "    ])\n",
        "\n",
        "    all_labels = np.concatenate([\n",
        "        labels, neg_labels_v1, neg_labels_v2, neg_labels_v3\n",
        "    ])\n",
        "\n",
        "    print(f\"Generated {len(all_labels)} total samples (original + negatives)\")\n",
        "\n",
        "    return all_metric_embs, all_text_embs, all_labels\n"
      ],
      "metadata": {
        "id": "ypax_J5peC4T"
      },
      "id": "ypax_J5peC4T",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# FEATURE ENGINEERING\n",
        "# =====================================\n",
        "\n",
        "def build_interaction_features(metric_embs, text_embs):\n",
        "    \"\"\"Create rich feature set from embedding pairs\"\"\"\n",
        "\n",
        "    # Simple concatenation\n",
        "    concatenated = np.hstack([metric_embs, text_embs])\n",
        "\n",
        "    # Element-wise interactions\n",
        "    absolute_diff = np.abs(metric_embs - text_embs)\n",
        "    element_product = metric_embs * text_embs\n",
        "\n",
        "    # Cosine similarity as additional feature\n",
        "    dot_products = np.sum(metric_embs * text_embs, axis=1)\n",
        "    metric_norms = np.linalg.norm(metric_embs, axis=1)\n",
        "    text_norms = np.linalg.norm(text_embs, axis=1)\n",
        "    cosine_sim = (dot_products / (metric_norms * text_norms + 1e-9)).reshape(-1, 1)\n",
        "\n",
        "    # Combine all features\n",
        "    feature_matrix = np.hstack([\n",
        "        concatenated,\n",
        "        absolute_diff,\n",
        "        element_product,\n",
        "        cosine_sim\n",
        "    ]).astype(np.float32)\n",
        "\n",
        "    return feature_matrix"
      ],
      "metadata": {
        "id": "XTgefqxYeC2P"
      },
      "id": "XTgefqxYeC2P",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# PYTORCH COMPONENTS\n",
        "# =====================================\n",
        "\n",
        "class ScoreDataset(Dataset):\n",
        "    \"\"\"Custom dataset for PyTorch training\"\"\"\n",
        "\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = torch.FloatTensor(features)\n",
        "        self.targets = torch.FloatTensor(targets)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]\n",
        "\n",
        "\n",
        "class ScoringNetwork(nn.Module):\n",
        "    \"\"\"Deep neural network for score prediction\"\"\"\n",
        "\n",
        "    def __init__(self, input_size):\n",
        "        super(ScoringNetwork, self).__init__()\n",
        "\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(input_size, 1024),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Linear(128, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x).squeeze(-1)"
      ],
      "metadata": {
        "id": "d4kcVg4ReCzr"
      },
      "id": "d4kcVg4ReCzr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# TRAINING & VALIDATION\n",
        "# =====================================\n",
        "\n",
        "def train_single_fold(train_data, val_data, config, fold_num):\n",
        "    \"\"\"Train one fold of cross-validation\"\"\"\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        train_data,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=True\n",
        "    )\n",
        "\n",
        "    val_loader = DataLoader(\n",
        "        val_data,\n",
        "        batch_size=config.BATCH_SIZE,\n",
        "        shuffle=False\n",
        "    )\n",
        "\n",
        "    # Initialize model\n",
        "    input_dim = train_data.features.shape[1]\n",
        "    model = ScoringNetwork(input_dim).to(config.DEVICE)\n",
        "\n",
        "    optimizer = torch.optim.AdamW(\n",
        "        model.parameters(),\n",
        "        lr=config.LEARNING_RATE,\n",
        "        weight_decay=1e-5\n",
        "    )\n",
        "\n",
        "    loss_function = nn.MSELoss()\n",
        "    best_val_loss = float('inf')\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(config.NUM_EPOCHS):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for features, targets in train_loader:\n",
        "            features = features.to(config.DEVICE)\n",
        "            targets = targets.to(config.DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(features)\n",
        "            loss = loss_function(predictions, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item() * features.size(0)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_predictions = []\n",
        "        val_targets = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for features, targets in val_loader:\n",
        "                features = features.to(config.DEVICE)\n",
        "                preds = model(features).cpu().numpy()\n",
        "                val_predictions.extend(preds)\n",
        "                val_targets.extend(targets.numpy())\n",
        "\n",
        "        val_predictions = np.array(val_predictions)\n",
        "        val_targets = np.array(val_targets)\n",
        "        val_rmse = np.sqrt(mean_squared_error(val_targets, val_predictions))\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_data)\n",
        "        print(f\"Fold {fold_num} | Epoch {epoch+1}/{config.NUM_EPOCHS} | \"\n",
        "              f\"Train Loss: {avg_train_loss:.4f} | Val RMSE: {val_rmse:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if val_rmse < best_val_loss:\n",
        "            best_val_loss = val_rmse\n",
        "            torch.save(model.state_dict(), f\"best_model_fold{fold_num}.pth\")\n",
        "\n",
        "    return best_val_loss\n",
        "\n",
        "\n",
        "def cross_validation_training(features, labels, config):\n",
        "    \"\"\"Perform k-fold cross-validation\"\"\"\n",
        "\n",
        "    kfold = StratifiedKFold(\n",
        "        n_splits=config.NUM_FOLDS,\n",
        "        shuffle=True,\n",
        "        random_state=config.RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    # Stratify by rounded labels\n",
        "    stratify_labels = np.round(labels).astype(int)\n",
        "\n",
        "    oof_predictions = np.zeros(len(features))\n",
        "    fold_scores = []\n",
        "\n",
        "    for fold_idx, (train_indices, val_indices) in enumerate(kfold.split(features, stratify_labels)):\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Training Fold {fold_idx + 1}/{config.NUM_FOLDS}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "        # Split data\n",
        "        X_train, X_val = features[train_indices], features[val_indices]\n",
        "        y_train, y_val = labels[train_indices], labels[val_indices]\n",
        "\n",
        "        train_dataset = ScoreDataset(X_train, y_train)\n",
        "        val_dataset = ScoreDataset(X_val, y_val)\n",
        "\n",
        "        # Train fold\n",
        "        fold_score = train_single_fold(\n",
        "            train_dataset,\n",
        "            val_dataset,\n",
        "            config,\n",
        "            fold_idx\n",
        "        )\n",
        "\n",
        "        fold_scores.append(fold_score)\n",
        "\n",
        "        # Generate OOF predictions\n",
        "        model = ScoringNetwork(features.shape[1]).to(config.DEVICE)\n",
        "        model.load_state_dict(torch.load(f\"best_model_fold{fold_idx}.pth\"))\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            val_features = torch.FloatTensor(X_val).to(config.DEVICE)\n",
        "            oof_predictions[val_indices] = model(val_features).cpu().numpy()\n",
        "\n",
        "    overall_score = np.mean(fold_scores)\n",
        "    print(f\"\\nAverage CV Score: {overall_score:.4f}\")\n",
        "\n",
        "    return oof_predictions, fold_scores\n"
      ],
      "metadata": {
        "id": "Bk_a7uSceu0X"
      },
      "id": "Bk_a7uSceu0X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =====================================\n",
        "# MAIN EXECUTION PIPELINE\n",
        "# =====================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Execute complete training pipeline\"\"\"\n",
        "\n",
        "    config = Config()\n",
        "    print(f\"Using device: {config.DEVICE}\\n\")\n",
        "\n",
        "    # Step 1: Load data\n",
        "    print(\"Loading datasets...\")\n",
        "    train_df, test_df, metrics_info = load_dataset_files()\n",
        "\n",
        "    train_df = create_combined_text(train_df)\n",
        "    test_df = create_combined_text(test_df)\n",
        "\n",
        "    print(f\"Training samples: {len(train_df)}\")\n",
        "    print(f\"Test samples: {len(test_df)}\\n\")\n",
        "\n",
        "    # Step 2: Generate embeddings\n",
        "    print(\"Generating embeddings...\")\n",
        "    embedder = EmbeddingGenerator(config.EMBEDDING_MODEL, config.DEVICE)\n",
        "\n",
        "    # Metric embeddings\n",
        "    metric_embedding_dict = embedder.encode_metrics(\n",
        "        train_df[\"metric_name\"].tolist()\n",
        "    )\n",
        "\n",
        "    train_metric_embs = np.vstack([\n",
        "        metric_embedding_dict[m] for m in train_df[\"metric_name\"]\n",
        "    ])\n",
        "\n",
        "    test_metric_embs = np.vstack([\n",
        "        metric_embedding_dict[m] for m in test_df[\"metric_name\"]\n",
        "    ])\n",
        "\n",
        "    # Text embeddings\n",
        "    print(\"Encoding training texts...\")\n",
        "    train_text_embs = embedder.encode_batch(\n",
        "        train_df[\"full_text\"].tolist(),\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    print(\"Encoding test texts...\")\n",
        "    test_text_embs = embedder.encode_batch(\n",
        "        test_df[\"full_text\"].tolist(),\n",
        "        show_progress=True\n",
        "    )\n",
        "\n",
        "    # Step 3: Augment with negative samples\n",
        "    print(\"\\nGenerating negative samples...\")\n",
        "    train_labels = train_df[\"score\"].values.astype(np.float32)\n",
        "\n",
        "    aug_metric_embs, aug_text_embs, aug_labels = generate_negative_samples(\n",
        "        train_metric_embs,\n",
        "        train_text_embs,\n",
        "        train_labels,\n",
        "        config\n",
        "    )\n",
        "\n",
        "    # Step 4: Build features\n",
        "    print(\"\\nBuilding features...\")\n",
        "    train_features = build_interaction_features(aug_metric_embs, aug_text_embs)\n",
        "    test_features = build_interaction_features(test_metric_embs, test_text_embs)\n",
        "\n",
        "    print(f\"Training feature shape: {train_features.shape}\")\n",
        "    print(f\"Test feature shape: {test_features.shape}\\n\")\n",
        "\n",
        "    # Step 5: Train models\n",
        "    print(\"Starting cross-validation training...\")\n",
        "    oof_preds, fold_scores = cross_validation_training(\n",
        "        train_features,\n",
        "        aug_labels,\n",
        "        config\n",
        "    )\n",
        "\n",
        "    # Step 6: Calibration\n",
        "    print(\"\\nApplying calibration...\")\n",
        "    calibrator = Ridge(alpha=1.0)\n",
        "    calibrator.fit(oof_preds.reshape(-1, 1), aug_labels)\n",
        "\n",
        "    oof_calibrated = calibrator.predict(oof_preds.reshape(-1, 1))\n",
        "    final_oof_score = np.sqrt(mean_squared_error(aug_labels, oof_calibrated))\n",
        "\n",
        "    print(f\"Calibrated OOF RMSE: {final_oof_score:.4f}\")\n",
        "\n",
        "    # Step 7: Test predictions\n",
        "    print(\"\\nGenerating test predictions...\")\n",
        "    test_preds_all_folds = []\n",
        "\n",
        "    for fold_idx in range(config.NUM_FOLDS):\n",
        "        model = ScoringNetwork(train_features.shape[1]).to(config.DEVICE)\n",
        "        model.load_state_dict(torch.load(f\"best_model_fold{fold_idx}.pth\"))\n",
        "        model.eval()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            test_tensor = torch.FloatTensor(test_features).to(config.DEVICE)\n",
        "            fold_preds = model(test_tensor).cpu().numpy()\n",
        "            test_preds_all_folds.append(fold_preds)\n",
        "\n",
        "    # Average and calibrate\n",
        "    test_preds_avg = np.mean(test_preds_all_folds, axis=0)\n",
        "    test_preds_final = calibrator.predict(test_preds_avg.reshape(-1, 1))\n",
        "    test_preds_final = np.clip(test_preds_final, 0, 10)\n",
        "\n",
        "    # Step 8: Create submission\n",
        "    submission = pd.DataFrame({\n",
        "        \"ID\": range(1, len(test_df) + 1),\n",
        "        \"score\": test_preds_final\n",
        "    })\n",
        "\n",
        "    submission.to_csv(\"submission.csv\", index=False)\n",
        "    print(\"\\nSubmission file created: submission.csv\")\n",
        "    print(f\"Prediction range: [{test_preds_final.min():.2f}, {test_preds_final.max():.2f}]\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "4S0A45efeuw3"
      },
      "id": "4S0A45efeuw3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3y8EdEeyeutu"
      },
      "id": "3y8EdEeyeutu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s6bC-ll8eurh"
      },
      "id": "s6bC-ll8eurh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wdl1Qfdjeuo5"
      },
      "id": "Wdl1Qfdjeuo5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9rzEVQLeumT"
      },
      "id": "W9rzEVQLeumT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gd0MTqvqeujp"
      },
      "id": "gd0MTqvqeujp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gM2NPKE8eugL"
      },
      "id": "gM2NPKE8eugL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JJsfGFtueueG"
      },
      "id": "JJsfGFtueueG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "di_iJZkXeubQ"
      },
      "id": "di_iJZkXeubQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cJJWK1kieuZM"
      },
      "id": "cJJWK1kieuZM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S2nSHJDNeuW4"
      },
      "id": "S2nSHJDNeuW4",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}